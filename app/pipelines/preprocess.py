"""
pipelines/hybrid_indexer.py

Qdrantã«å¯¾ã—ã¦ Denseï¼ˆOpenAI Embeddingï¼‰+ Sparseï¼ˆBM25ï¼‰ã‚’ç™»éŒ²ã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µã€‚
BM25ã®èªžå½™æƒ…å ±ã‚’ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³metadataã¨ã—ã¦ä¿å­˜ã—ã€å¾Œã§æ¤œç´¢å´ã§å®Œå…¨å¾©å…ƒã§ãã‚‹ã€‚
"""

import os
import re
import json
import time
import uuid
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional

from tqdm import tqdm
from qdrant_client import QdrantClient, models
from openai import OpenAI
from openai import RateLimitError, APIError

from app.core.config import settings
from app.services.bm25_sparse import BM25Sparse


# ============================================================
# è¨­å®š
# ============================================================
CHAT_MODEL = settings.OPENAI_CHAT_MODEL
EMBED_MODEL = settings.OPENAI_EMBED_MODEL
QDRANT_PATH = os.path.abspath(settings.QDRANT_PATH)
COLLECTION_NAME = settings.QDRANT_COLLECTION
OPENAI_API_KEY = settings.OPENAI_API_KEY

CAPTION_MAX_WORKERS = 5
EMBED_BATCH_SIZE = 64
QDRANT_BATCH_SIZE = 256


# ============================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================
def iter_json(path: str):
    """JSONL ã¾ãŸã¯ JSONé…åˆ—ã‚’èª­ã¿è¾¼ã‚€"""
    with open(path, "r", encoding="utf-8") as f:
        first = f.read(1)
        f.seek(0)
        if first == "[":
            for item in json.load(f):
                yield item
        else:
            for line in f:
                if line.strip():
                    yield json.loads(line)


def stable_uuid(val: str) -> str:
    """æ–‡å­—åˆ—ã‹ã‚‰å®‰å®šçš„ãªUUIDã‚’ç”Ÿæˆ"""
    return str(uuid.uuid5(uuid.NAMESPACE_DNS, val))


def extract_image_refs(product: Dict) -> List[str]:
    """ç”»åƒURLã‚’æŠ½å‡º"""
    imgs = product.get("images", [])
    refs = []
    for img in imgs:
        if isinstance(img, dict) and "large" in img:
            refs.append(img["large"])
        elif isinstance(img, str):
            refs.append(img)
    return refs[:1]


# ============================================================
# ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ
# ============================================================
CAPTION_SYSTEM_PROMPT = """
ã‚ãªãŸã¯ECå•†å“ã®ç”»åƒã«å¯¾ã™ã‚‹äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
è‹±èªžã§ã€å®¢è¦³çš„ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’1ã¤ï¼ˆ3ã€œ5æ–‡ï¼‰å‡ºåŠ›ã—ã¾ã™ã€‚
- ç”»åƒã«è¦‹ãˆã‚‹å†…å®¹ã€ã¾ãŸã¯æä¾›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ/ãƒ¦ãƒ¼ã‚¶æ„å›³ã«æ˜Žç¤ºã•ã‚ŒãŸäº‹å®Ÿã®ã¿ã‚’æ›¸ãã“ã¨ã€‚
- ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ›ç›¾ã™ã‚‹å ´åˆã¯ç”»åƒã‚’å„ªå…ˆã™ã‚‹ã“ã¨ã€‚
- ãƒžãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°èª¿ã‚„ä¸»è¦³çš„è©•ä¾¡ã€æŽ¨æ¸¬ã®æ–­å®šã¯ç¦æ­¢ã€‚äº‹å®Ÿã®ã¿ã€ç°¡æ½”ã«ã€‚
- å‡ºåŠ›ã¯ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æœ¬æ–‡ã®ã¿ã€‚

ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³å‘ã‘ã«ã€è¦‹ãˆã‚‹ç¯„å›²ã§æ¬¡ã®å¯è¦–å±žæ€§ã‚’å„ªå…ˆçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š
- ã‚·ãƒ«ã‚¨ãƒƒãƒˆ/ãƒ•ã‚£ãƒƒãƒˆãƒ»ä¸ˆã€ãƒãƒƒã‚¯ãƒ©ã‚¤ãƒ³ãƒ»è¢–ã€ã‚¦ã‚¨ã‚¹ãƒˆ/è£¾ã®ä½œã‚Šã€é–‹é–‰ï¼ˆãƒœã‚¿ãƒ³/ã‚¸ãƒƒãƒ‘ãƒ¼/é‡‘å…·ï¼‰ã€
  ãƒã‚±ãƒƒãƒˆ/ãƒ™ãƒ«ãƒˆ/ãƒ©ã‚¤ãƒ‹ãƒ³ã‚°ã€ç´ ææ„Ÿãƒ»ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼ˆsheer/opaque/glossy/drape/stretchï¼‰ã€
  ãƒ‘ã‚¿ãƒ¼ãƒ³/è£…é£¾ï¼ˆlace/rhinestonesç­‰ï¼‰ã€è‰²ãƒ»colorwayã€ã‚»ãƒƒãƒˆ/åŒæ¢±ã€ã‚¢ã‚¯ã‚»ã‚µãƒªãƒ¼ç‰¹æœ‰ã®è¦ç´ ï¼ˆä¾‹ï¼šãƒ¬ãƒ³ã‚ºè‰²/å½¢çŠ¶ï¼‰ã€‚

ç›®çš„ãƒ»å­£ç¯€ãƒ»ã‚ªã‚±ãƒ¼ã‚¸ãƒ§ãƒ³ã®æ‰±ã„ï¼ˆæ˜Žç¤ºãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰ï¼š
- å…¥åŠ›ã« Intent/Season/Occasion ãŒä¸Žãˆã‚‰ã‚Œã¦ã„ã‚Œã°ã€æœ€å¾Œã®1æ–‡ã§ã€Œè¦‹ãŸç›®ã®æ ¹æ‹ ã€ã‚’æ·»ãˆã¦è»½ãçµã³ã¤ã‘ã‚‹ã“ã¨ã€‚
  ä¾‹ï¼šæµ·/å¤ â†’ ã€Œlightweight-looking, open-weave, quick-drying-lookingã€ãªã©â€œè¦‹ãŸç›®â€è¨˜è¿°ã«ç•™ã‚ã‚‹ã€‚
- æ€§èƒ½ãƒ»æ©Ÿèƒ½ï¼ˆUVä¿è­·ãƒ»å¸æ±—é€Ÿä¹¾ãƒ»é˜²æ°´ç­‰ï¼‰ã¯ã€ç”»åƒã‚„ãƒ†ã‚­ã‚¹ãƒˆã§æ˜Žè¨˜ã•ã‚Œãªã„é™ã‚Šä¸»å¼µã—ãªã„ã€‚
"""

CAPTION_USER_PROMPT = """
å…¥åŠ›ï¼š
- ç”»åƒ
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ¬ è½ã‚ã‚Šï¼‰ï¼š
  - Title: {title}
  - Store: {store}
  - Features: {features}

ã‚¿ã‚¹ã‚¯ï¼š
ç”»åƒã§ç¢ºèªã§ãã‚‹å±žæ€§ã‚’æœ€å„ªå…ˆã—ã€çŸ›ç›¾ã®ãªã„ç¯„å›²ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¦ãƒ¼ã‚¶æ„å›³ã®æ˜Žç¤ºçš„äº‹å®Ÿã‚‚çµ±åˆã—ã¦ã€
è‹±èªžã§3ã€œ5æ–‡ã®äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚
- å¯èƒ½ãªç¯„å›²ã§ã€ã‚·ãƒ«ã‚¨ãƒƒãƒˆ/ä¸ˆã€ãƒãƒƒã‚¯ãƒ©ã‚¤ãƒ³/è¢–ã€æ§‹é€ çš„ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ã€é–‹é–‰ã€ãƒã‚±ãƒƒãƒˆ/ãƒ™ãƒ«ãƒˆ/ãƒ©ã‚¤ãƒ‹ãƒ³ã‚°ã€
  ç´ ææ„Ÿ/ãƒ†ã‚¯ã‚¹ãƒãƒ£ã€ãƒ‘ã‚¿ãƒ¼ãƒ³/è£…é£¾ã€è‰²/ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚»ãƒƒãƒˆ/åŒæ¢±ã€ã‚¢ã‚¯ã‚»ã‚µãƒªãƒ¼å›ºæœ‰è¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
- Intent/Season/Occasion ãŒä¸Žãˆã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€æœ€å¾Œã®1æ–‡ã§ã€Œè¦‹ãŸç›®ã«åŸºã¥ãé©åˆç†ç”±ã€ã‚’ç°¡æ½”ã«è¿°ã¹ã¦ã‚ˆã„
  ï¼ˆä¾‹ï¼šé€šæ°—æ€§ã®ã‚ã‚‹ãƒ¡ãƒƒã‚·ãƒ¥ã€è»½ãè¦‹ãˆã‚‹ãƒ‰ãƒ¬ãƒ¼ãƒ—ã€é–‹æ”¾çš„ãªã‚µãƒ³ãƒ€ãƒ«ã‚¹ãƒˆãƒ©ãƒƒãƒ—ç­‰ï¼‰ã€‚
- æ€§èƒ½ä¸»å¼µï¼ˆUVãƒ»å¸æ±—é€Ÿä¹¾ãƒ»ä¿æ¸©ãªã©ï¼‰ã¯ã€ç”»åƒ/ãƒ†ã‚­ã‚¹ãƒˆã§æ˜Žè¨˜ã•ã‚Œãªã„é™ã‚Šé¿ã‘ã¦ãã ã•ã„ã€‚
å‡ºåŠ›ã¯ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æœ¬æ–‡ã®ã¿ã€‚
"""



def caption_images(image_urls: List[str], title: str, store: str, features: str) -> Optional[str]:
    """1å•†å“åˆ†ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆå …ç‰¢ãªãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
    if not image_urls:
        return None

    client = OpenAI(api_key=OPENAI_API_KEY)
    user_prompt = CAPTION_USER_PROMPT.format(
        title=title or "",
        store=store or "",
        features=features or "None",
    )

    # ç”»åƒã¯1æžšãšã¤é€ã‚‹æƒ³å®š
    messages = [
        {"role": "system", "content": CAPTION_SYSTEM_PROMPT},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": user_prompt},
                {"type": "image_url", "image_url": {"url": image_urls[0]}},
            ],
            "reasoning_effort": "minimal",
            "verbosity": "low",
        },
    ]

    MAX_RETRIES = 5
    for attempt in range(MAX_RETRIES):
        try:
            r = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=messages,
                temperature=0.2,
                timeout=60,  # å¿µã®ãŸã‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæŒ‡å®š
            )
            caption = r.choices[0].message.content.strip()
            return caption

        except RateLimitError as e:
            # âœ… ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ™‚ï¼šæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‹ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ãƒªãƒ¼ãƒ—
            wait = min(30, 2 ** attempt + random.uniform(0, 3))
            print(f"âš ï¸ RateLimitError: retrying in {wait:.1f}s ({attempt+1}/{MAX_RETRIES})")
            time.sleep(wait)
        except APIError as e:
            # âœ… APIã‚¨ãƒ©ãƒ¼ï¼ˆ5xxç³»ï¼‰ï¼šæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§å†è©¦è¡Œ
            wait = min(20, 2 ** attempt)
            print(f"âš ï¸ APIError: {e}. retrying in {wait}s")
            time.sleep(wait)
        except Exception as e:
            # ãã®ä»–ã‚¨ãƒ©ãƒ¼ã¯1å›žã ã‘å¾…ã£ã¦ç¶šè¡Œ
            print(f"âŒ Caption generation failed ({attempt+1}/{MAX_RETRIES}): {e}")
            time.sleep(3)
    print("ðŸš« Caption generation failed after maximum retries.")
    return None


# ============================================================
# Embedding
# ============================================================
def embed_parallel(texts: List[str], model_name: str = EMBED_MODEL) -> List[List[float]]:
    """OpenAIåŸ‹ã‚è¾¼ã¿ã‚’ãƒãƒƒãƒç”Ÿæˆ"""
    client = OpenAI(api_key=OPENAI_API_KEY)
    vectors = []
    for i in tqdm(range(0, len(texts), EMBED_BATCH_SIZE), desc="embedding"):
        batch = texts[i : i + EMBED_BATCH_SIZE]
        try:
            r = client.embeddings.create(model=model_name, input=batch)
            vectors.extend([d.embedding for d in r.data])
        except Exception as e:
            print(f"âŒ Embedding failed at batch {i}: {e}")
            time.sleep(5)
    return vectors


# ============================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================================================
# ------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼šJSON â†’ Qdrant (dense + sparse + payload + BM25 meta)
def run(input_path: str, qdrant_path: str = QDRANT_PATH):
    os.makedirs(qdrant_path, exist_ok=True)
    qdrant = QdrantClient(path=qdrant_path)

    products = list(iter_json(input_path))
    all_texts = []
    payloads = []

    # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆä¸¦åˆ—åŒ–ï¼‰
    def process_prod(prod):
        pid = prod.get("asin") or stable_uuid(json.dumps(prod))
        title = prod.get("title", "")
        store = prod.get("store", "")
        features = "; ".join(prod.get("features", []))
        images = extract_image_refs(prod)
        caption = caption_images(images, title, store, features)
        search_text = " ".join([title, features, caption or ""]).strip()
        payload = {**prod, "_id": pid, "_caption": caption, "_search_text": search_text}
        return payload, search_text

    print(f"ðŸ§  Generating captions in parallel ({CAPTION_MAX_WORKERS} workers)...")
    with ThreadPoolExecutor(max_workers=CAPTION_MAX_WORKERS) as executor:
        futures = [executor.submit(process_prod, p) for p in products]
        for fut in tqdm(as_completed(futures), total=len(futures), desc="caption"):
            payload, text = fut.result()
            payloads.append(payload)
            all_texts.append(text)

    # Dense embedding
    dense = embed_parallel(all_texts, EMBED_MODEL)

    # BM25 ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    bm25 = BM25Sparse(all_texts)

    # Qdrant ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆdense + sparseï¼‰
    dim = len(dense[0])
    qdrant.recreate_collection(
        collection_name=COLLECTION_NAME,
        vectors_config={
            "text-dense": models.VectorParams(size=dim, distance=models.Distance.COSINE)
        },
        sparse_vectors_config={
            "text-sparse": models.SparseVectorParams()
        }
    )

    # BM25 ãƒ¡ã‚¿ä¿å­˜ï¼ˆãƒ€ãƒŸãƒ¼ Pointï¼‰
    bm25.save_to_qdrant(qdrant, COLLECTION_NAME)

    # å„å•†å“ upsert
    points = []
    for vec, text, payload in zip(dense, all_texts, payloads):
        idx, vals = bm25.transform_doc(text)
        uid = str(uuid.uuid5(uuid.NAMESPACE_DNS, str(payload["_id"])))
        points.append(
            models.PointStruct(
                id=uid,
                vector={
                    "text-dense": vec,
                    "text-sparse": models.SparseVector(indices=idx, values=vals),
                },
                payload=payload,
            )
        )
        if len(points) >= QDRANT_BATCH_SIZE:
            qdrant.upsert(collection_name=COLLECTION_NAME, points=points)
            points.clear()
    if points:
        qdrant.upsert(collection_name=COLLECTION_NAME, points=points)

    print(f"âœ… Hybrid index built: {len(payloads)} points (BM25 meta included)")