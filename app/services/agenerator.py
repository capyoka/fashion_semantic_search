import logging
from typing import List
import os, json, re, ast
from openai import AsyncOpenAI

# Loggerè¨­å®š
logger = logging.getLogger(__name__)

# =========================================================
# âœ³ï¸ å¤–éƒ¨ã§å®šç¾©ã§ãã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¾¤
# =========================================================

SYSTEM_PROMPT_BASE = "You are a helpful assistant. Answer concisely in Japanese."

SYSTEM_PROMPT_BASE = """
You are a helpful assistant. Answer concisely in Japanese.
"""

PROMPT_REWRITE =  """
ã‚ãªãŸã¯ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³å•†å“ã®æ¤œç´¢æ”¯æ´ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãŒå…¥åŠ›ã—ãŸè‡ªç„¶æ–‡ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã€æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã§æ‰±ã„ã‚„ã™ã„2ç¨®é¡ã®è‹±èªã‚¯ã‚¨ãƒªã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

ç›®çš„ï¼š
1. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆsemantic searchï¼‰ã«é©ã—ãŸè‡ªç„¶ãªè‹±æ–‡ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆsemantic_queryï¼‰
2. å˜èªæ¤œç´¢ï¼ˆBM25ï¼‰ã«é©ã—ãŸä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®åˆ—ï¼ˆbm25_queryï¼‰

ãƒ«ãƒ¼ãƒ«ï¼š
- å‡ºåŠ›ã¯è‹±èªã®JSONå½¢å¼ã§è¡Œã†ã€‚
- semantic_query ã¯1æ–‡ã¾ãŸã¯1ãƒ•ãƒ¬ãƒ¼ã‚ºã§ã€è‡ªç„¶è¨€èªã«è¿‘ã„ãŒç°¡æ½”ãªæ¤œç´¢æ–‡ã«ã™ã‚‹ã€‚
- bm25_query ã¯ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã®ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç¾¤ã«ã™ã‚‹ã€‚
- ãƒ¦ãƒ¼ã‚¶ãŒæ˜ç¤ºã—ã¦ã„ãªã„å±æ€§ï¼ˆç´ æã€è‰²ã€ç”¨é€”ãªã©ï¼‰ã‚’æ¨æ¸¬ã—ã¦è¿½åŠ ã—ãªã„ã€‚
- ä¸»è¦³çš„ãªè¡¨ç¾ï¼ˆã‹ã‚ã„ã„ã€å†™çœŸæ˜ ãˆã€äººæ°—ãªã©ï¼‰ã¯ã€è¦‹ãŸç›®ã‚„ç”¨é€”ã«åŸºã¥ãä¸­ç«‹çš„ãªè¡¨ç¾ã¸ç½®ãæ›ãˆã‚‹ã€‚
  ä¾‹ï¼šã€Œã‹ã‚ã„ã„æœã€â†’ã€Œstylish outfitã€, ã€Œå†™çœŸæ˜ ãˆã€â†’ã€Œbright and eye-catchingã€
- æ¤œç´¢èªã¨ã—ã¦æœ‰åŠ¹ãªè¦ç´ ï¼ˆã‚«ãƒ†ã‚´ãƒªã€ç”¨é€”ã€å­£ç¯€ã€è‰²ã€ç´ æã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚ªã‚±ãƒ¼ã‚¸ãƒ§ãƒ³ãªã©ï¼‰ã‚’ä¸­å¿ƒã«æ§‹æˆã™ã‚‹ã€‚
- å‡ºåŠ›å½¢å¼ã¯å¿…ãšä»¥ä¸‹ã®è¦ç´ ã‚’æŒã¤JSONå½¢å¼ã«å¾“ã†ï¼š

  semantic_query: ...,
  bm25_query: ...


ãƒ¦ãƒ¼ã‚¶ã‚¯ã‚¨ãƒª: {user_query}
å‡ºåŠ›:
"""

PROMPT_RERANK = """
ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ã®æ¤œç´¢æ„å›³ã¨ã€å€™è£œã®å•†å“èª¬æ˜ãƒªã‚¹ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶è³ªå•: {user_query}

å€™è£œä¸€è¦§ï¼ˆ[]å†…ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰:
{enumerated}

æŒ‡ç¤º:
- ãƒ¦ãƒ¼ã‚¶ãŒæœ€ã‚‚æ¬²ã—ã„é †ã«ä¸¦ã¹æ›¿ãˆã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯ JSON é…åˆ—ã§ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå·ã®ã¿ï¼ˆä¾‹: [2,0,1]ï¼‰ã€‚
- ä½™è¨ˆãªæ–‡å­—ã¯å‡ºã•ãšã€JSONã ã‘ã‚’è¿”ã™ã€‚
"""

# =========================================================
# âœ³ï¸ ã‚¯ãƒ©ã‚¹å®šç¾©
# =========================================================

class AsyncGenerator:
    def __init__(self, model: str, fast_model: str = None):
        key = os.getenv("OPENAI_API_KEY")
        if not key:
            raise RuntimeError("OPENAI_API_KEY is not set.")
        self.client = AsyncOpenAI(api_key=key)
        self.model = model
        self.fast_model = fast_model

    # --- ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆ ---
    async def rewrite_query(self, user_query: str, prompt_template: str = PROMPT_REWRITE) -> str:
        logger.info(f"ğŸ”„ Starting query rewrite for: '{user_query}'")
        logger.debug(f"Using model: {self.fast_model if self.fast_model else self.model}")
        
        prompt = prompt_template.format(user_query=user_query)
        msgs = [
            {"role": "system", "content": "Japanese concise query rewriter."},
            {"role": "user", "content": prompt},
        ]
        
        try:
            r = await self.client.chat.completions.create(
                model=self.fast_model if self.fast_model else self.model,
                messages=msgs,
                response_format={"type": "json_object"},
            )
            res = r.choices[0].message.content
            logger.debug(f"Raw LLM response: {res}")
            
            result = ast.literal_eval(res)
            semantic_query = result["semantic_query"]
            bm25_query = result["bm25_query"]
            
            logger.info(f"âœ… Query rewrite successful:")
            logger.info(f"   Original: '{user_query}'")
            logger.info(f"   Semantic: '{semantic_query}'")
            logger.info(f"   BM25: '{bm25_query}'")
            
            return semantic_query, bm25_query
        except Exception as e:
            logger.error(f"âŒ Query rewrite failed: {e}")
            logger.error(f"   Input query: '{user_query}'")
            logger.error(f"   Model: {self.fast_model if self.fast_model else self.model}")
            raise

    # --- LLMãƒªãƒ©ãƒ³ã‚¯ ---
    async def rerank(
        self,
        user_query: str,
        items: List[str],
        prompt_template: str = PROMPT_RERANK,
    ) -> list[int]:
        logger.debug(f"Reranking {len(items)} items for query: '{user_query}'")
        enumerated = "\n".join([f"[{i}] {t}" for i, t in enumerate(items)])
        prompt = prompt_template.format(user_query=user_query, enumerated=enumerated)
        msgs = [
            {"role": "system", "content": "You are a ranking model. Return only a JSON array of integers."},
            {"role": "user", "content": prompt},
        ]
        try:
            r = await self.client.chat.completions.create(
                model=self.model,
                messages=msgs,
                reasoning_effort="minimal",
                verbosity="low",
            )
            text = r.choices[0].message.content.strip()

            # JSONãƒ‘ãƒ¼ã‚¹ï¼ˆå£Šã‚Œã¦ã„ãŸã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            try:
                arr = json.loads(text)
                if isinstance(arr, list) and all(isinstance(x, int) for x in arr):
                    logger.debug(f"Reranking successful: {len(arr)} items ranked")
                    return arr
            except Exception as e:
                logger.warning(f"Failed to parse rerank result: {e}")

            # å£Šã‚Œã¦ã„ãŸã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé †
            logger.warning("Rerank failed, using default order")
            return list(range(len(items)))
        except Exception as e:
            logger.error(f"Rerank request failed: {e}")
            return list(range(len(items)))
